{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f859ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "\n",
    "# DESCRIPTION: This notebook contains code for extracting and saving a random subset of the test data from the EEG Epipleptic\n",
    "# dataset at: https://data.mendeley.com/datasets/5pc2j46cbc/1. In the notebook, the number of samples in the extracted \n",
    "# random subset is denoted by \"number_of_test_samples.\" By default, the notebook sets \"number_of_test_samples\" to 10, but the \n",
    "# user can change this to any other value, albeit users are STRONGLY ADVISED to AVOID values greater than 200, due to AWS API\n",
    "# Gateway's 30 seconds timeout hard limit.\n",
    "\n",
    "# Subsequent to extraction, the extracted random subset is saved to the user's local disk at the location indicated by \n",
    "# variable \"data_file_path\". By default, \"data_file_path\" is set to 'data_slice.csv', but the user can change it if they wish. \n",
    "\n",
    "# Also the program saves the ground truth labels associated with the extracted data. It uses variable \"ground_truth_file_path\" \n",
    "# to hold the path to which the ground truth labels is saved. By default the program sets variable \"ground_truth_file_path\" to\n",
    "# 'ground_truth.txt', but the user can change this to some other value if they wish. The purpose of saving the ground truth \n",
    "# labels is to enable the user compare the ground truth labels with the values output from the EEG classification API, when the \n",
    "# API is invoked with the data saved in 'data_slice.csv' \n",
    "\n",
    "# Finally, the notebook utilizes the \"user_seed\" variable to achieve reproducilibity of results and control randomness. \n",
    "# For instance, running the notebook several times with user_seed = 40 and number_of_test_samples = 100 will extract EXACTLY\n",
    "# the same set of samples from the dataset for all runs, because the user_seed was not changed from one run to the next. \n",
    "# To extract different sets of samples from one run to the next, the user needs to change the user_seed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number_of_test_samples = 10\n",
    "data_file_path = 'data_slice.csv' \n",
    "ground_truth_file_path = 'ground_truth.csv'\n",
    "user_seed = 40\n",
    "\n",
    "\n",
    "def load_data_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = np.load(io.BytesIO(response.content)) \n",
    "    return data\n",
    "\n",
    "def save_data_slice(x, inds, file_path):\n",
    "    data_slice = x[inds, :, :]\n",
    "    numb_samps, dim_1, dim_2 = data_slice.shape\n",
    "    data_slice = data_slice.reshape(numb_samps, dim_1*dim_2)\n",
    "    np.savetxt(file_path, data_slice, delimiter = ',' )\n",
    "\n",
    "def get_random_indices(required_size, max_index):\n",
    "    \n",
    "    rng = np.random.default_rng(seed=user_seed)\n",
    "    a = np.arange(max_index)\n",
    "    b = rng.choice(a, size = required_size, replace = False)\n",
    "    return b\n",
    "\n",
    "def save_ground_truth(gt_dict):\n",
    "    f = open('ground_truth.txt', 'w')\n",
    "    for i, dict_key in enumerate(gt_dict):\n",
    "        print(i + 1, gt_dict[dict_key])\n",
    "        f.write( str(i + 1) + ' ' + gt_dict[dict_key] + '\\n')\n",
    "    f.close\n",
    "\n",
    "\n",
    "url_x = 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/93b81166-0e48-4dc0-ac20-b7167f7606c5/file_downloaded'\n",
    "test_data = load_data_from_url (url_x)\n",
    "rand_inds = get_random_indices(number_of_test_samples , int(test_data.shape[2])) \n",
    "\n",
    "random_test_data = save_data_slice(test_data, rand_inds, data_file_path)\n",
    "\n",
    "url_y = 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/adf1c2fd-81ef-4f87-86cc-56d75bba8c31/file_downloaded'\n",
    "labels = load_data_from_url (url_y)\n",
    "ground_truth = labels[rand_inds]\n",
    "\n",
    "label_dict = {0: 'Normal', 1: 'Complex Partial Seizure', 2: 'Electrographic Seizure', 3: 'Video-detected Seizure' }\n",
    "dict_inds = list(range(number_of_test_samples))\n",
    "ground_truth_dict = {dict_inds[i] + 1: label_dict[ground_truth[i]] for i in range(number_of_test_samples)}\n",
    "print('GROUND TRUTH: \\n')\n",
    "save_ground_truth(ground_truth_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa2b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e74f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b7062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e71572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matplot_env",
   "language": "python",
   "name": "matplot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
